{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1BVZL1yIsKFRHpPnZv9cpt_a8FpTHmDMq",
      "authorship_tag": "ABX9TyNkYzZ+5AnsG8DupzL5qJOg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lottle2008/MOOCCube-Transformer-Recommendation/blob/main/gai_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h58OgYM_vJrQ",
        "outputId": "9436a994-d5da-44f8-adc7-897c544edd1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# âœ… é€‚é…çœŸå®æ•°æ®é›†çš„ä»£ç ï¼ˆASSISTments 2017ï¼‰\n",
        "# åŸºäºæŒ‡å®šè·¯å¾„å’ŒçœŸå®åˆ—åä¿®æ”¹\n",
        "# ==========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# --------------------------\n",
        "# 1ï¸âƒ£ æŒ‚è½½Google Driveï¼ˆè®¿é—®æ•°æ®é›†ï¼‰\n",
        "# --------------------------\n",
        "print(\"ğŸ”— æŒ‚è½½Google Driveä»¥è®¿é—®æ•°æ®é›†...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"âœ… DriveæŒ‚è½½å®Œæˆ\")\n",
        "\n",
        "# --------------------------\n",
        "# 2ï¸âƒ£ è¯»å–æ•°æ®é›†ï¼ˆä½¿ç”¨æŒ‡å®šè·¯å¾„ï¼‰\n",
        "# --------------------------\n",
        "# æ•°æ®é›†è·¯å¾„ï¼ˆæŒ‰ä½ çš„è·¯å¾„ä¿®æ”¹ï¼‰\n",
        "DATASET_PATH = \"/content/drive/MyDrive/gai/data/student_log_1.csv\"\n",
        "\n",
        "print(\"\\nğŸ“‚ è¯»å–æ•°æ®é›†...\")\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "print(f\"åŸå§‹æ•°æ®é‡: {len(df):,}\")\n",
        "\n",
        "# --------------------------\n",
        "# 3ï¸âƒ£ æ•°æ®é¢„å¤„ç†ï¼ˆä½¿ç”¨çœŸå®åˆ—åæ˜ å°„ï¼‰\n",
        "# æ ¸å¿ƒåˆ—æ˜ å°„å…³ç³»ï¼š\n",
        "# åŸé€»è¾‘åˆ—å â†’ çœŸå®æ•°æ®é›†åˆ—å\n",
        "# user_id â†’ ITEST_idï¼ˆå­¦ç”Ÿå”¯ä¸€æ ‡è¯†ï¼‰\n",
        "# problem_id â†’ problemIdï¼ˆé¢˜ç›®IDï¼‰\n",
        "# skill_id â†’ skillï¼ˆçŸ¥è¯†ç‚¹åç§°ï¼‰\n",
        "# correct â†’ correctï¼ˆç­”é¢˜æ­£ç¡®æ€§ï¼‰\n",
        "# order_id â†’ actionIdï¼ˆäº¤äº’é¡ºåºIDï¼‰\n",
        "# --------------------------\n",
        "\n",
        "# ä¿ç•™å…³é”®åˆ—ï¼ˆä½¿ç”¨çœŸå®åˆ—åï¼‰\n",
        "df = df[['ITEST_id', 'problemId', 'skill', 'correct', 'actionId']]\n",
        "\n",
        "# å‰”é™¤å…³é”®åˆ—ç¼ºå¤±çš„è®°å½•\n",
        "df = df.dropna(subset=['ITEST_id', 'problemId', 'skill'])\n",
        "\n",
        "# é™åˆ¶è§„æ¨¡ï¼šå–å‰5000ä¸ªç”¨æˆ·ï¼ˆä¾¿äºColabè®­ç»ƒï¼‰\n",
        "selected_users = df['ITEST_id'].unique()[:5000]\n",
        "df = df[df['ITEST_id'].isin(selected_users)]\n",
        "\n",
        "# æ˜ å°„ä¸ºå­—ç¬¦ä¸²IDï¼ˆé¿å…æ•°å€¼å‹IDè¢«è¯¯å¤„ç†ï¼‰\n",
        "df['ITEST_id'] = df['ITEST_id'].astype(str)\n",
        "df['problemId'] = df['problemId'].astype(str)\n",
        "df['skill'] = df['skill'].astype(str)  # çŸ¥è¯†ç‚¹åç§°è½¬ä¸ºå­—ç¬¦ä¸²\n",
        "\n",
        "# --------------------------\n",
        "# 4ï¸âƒ£ ç”Ÿæˆç›®æ ‡æ–‡ä»¶ç»“æ„ï¼ˆä¸åŸé€»è¾‘å¯¹é½ï¼‰\n",
        "# --------------------------\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# users.csvï¼ˆç”¨æˆ·è¡¨ï¼‰\n",
        "users = pd.DataFrame({'user_id': df['ITEST_id'].unique()})\n",
        "users.to_csv(\"data/users.csv\", index=False)\n",
        "\n",
        "# videos.csvï¼ˆé¢˜ç›®è¡¨ï¼Œæ¨¡æ‹Ÿè§†é¢‘èŠ‚ç‚¹ï¼‰\n",
        "videos = pd.DataFrame({'video_id': df['problemId'].unique()})\n",
        "videos.to_csv(\"data/videos.csv\", index=False)\n",
        "\n",
        "# video_concept_edges.csvï¼ˆé¢˜ç›®â€”çŸ¥è¯†ç‚¹æ˜ å°„ï¼‰\n",
        "video_concept = df[['problemId', 'skill']].drop_duplicates()\n",
        "video_concept.columns = ['video_id', 'concept_id']  # é‡å‘½åä¸ºæ¨¡å‹éœ€è¦çš„åˆ—å\n",
        "video_concept.to_csv(\"data/video_concept_edges.csv\", index=False)\n",
        "\n",
        "# watch_logs.csvï¼ˆç”¨æˆ·â€”é¢˜ç›®äº¤äº’æ—¥å¿—ï¼‰\n",
        "logs = df[['ITEST_id', 'problemId', 'correct', 'actionId']]\n",
        "logs.columns = ['user_id', 'video_id', 'is_correct', 'timestamp']  # é€‚é…æ¨¡å‹å­—æ®µ\n",
        "logs.to_csv(\"data/watch_logs.csv\", index=False)\n",
        "\n",
        "# --------------------------\n",
        "# 5ï¸âƒ£ è¾“å‡ºç»“æœæ£€æŸ¥\n",
        "# --------------------------\n",
        "print(\"\\nâœ… æ•°æ®æ–‡ä»¶å·²ç”Ÿæˆï¼Œå…±åŒ…å«ï¼š\")\n",
        "for f in os.listdir(\"data\"):\n",
        "    file_path = os.path.join(\"data\", f)\n",
        "    print(f\" - {f}: {len(pd.read_csv(file_path)):,} æ¡è®°å½•\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyVRoyS-wJuM",
        "outputId": "5aa75d7e-6815-4897-ff63-9944527beb74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”— æŒ‚è½½Google Driveä»¥è®¿é—®æ•°æ®é›†...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… DriveæŒ‚è½½å®Œæˆ\n",
            "\n",
            "ğŸ“‚ è¯»å–æ•°æ®é›†...\n",
            "åŸå§‹æ•°æ®é‡: 231,403\n",
            "\n",
            "âœ… æ•°æ®æ–‡ä»¶å·²ç”Ÿæˆï¼Œå…±åŒ…å«ï¼š\n",
            " - watch_logs.csv: 231,403 æ¡è®°å½•\n",
            " - videos.csv: 3,415 æ¡è®°å½•\n",
            " - users.csv: 334 æ¡è®°å½•\n",
            " - video_concept_edges.csv: 3,425 æ¡è®°å½•\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrYxhJsjuo9N",
        "outputId": "4a3aa7a4-b1bf-4025-a40b-daf79f70fef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2177413088.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('user_id', group_keys=False).apply(split_user_grp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… v2 æ•°æ®å‡†å¤‡å®Œæˆ: /content/data_v2\n"
          ]
        }
      ],
      "source": [
        "# ==========================\n",
        "# Stage 1 (v2): æ•°æ®æ„å»ºï¼ˆæ—¶åºåˆ‡åˆ† & é˜²æ³„éœ²ï¼‰\n",
        "# è¾“å…¥: assist2017.csv ï¼ˆæˆ–ä½ å·²ç”Ÿæˆçš„ /content/data/*.csvï¼‰\n",
        "# è¾“å‡º: /content/data_v2/{train,val,test}_{logs}.csv + åŸºç¡€èŠ‚ç‚¹è¡¨\n",
        "# ==========================\n",
        "import os, pandas as pd, numpy as np\n",
        "\n",
        "ROOT = \"/content\"\n",
        "OUT  = os.path.join(ROOT, \"data_v2\")\n",
        "SRC  = os.path.join(ROOT, \"data\")  # è‹¥ä½ å·²æœ‰ Stage1 ç”Ÿæˆçš„æ•°æ®ï¼Œç›´æ¥æŒ‡å‘å®ƒ\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "# 1) è½½å…¥åŸ logsï¼ˆæ²¿ç”¨ä½ å‰é¢ç”Ÿæˆçš„ watch_logs.csvï¼‰\n",
        "df = pd.read_csv(os.path.join(SRC, \"watch_logs.csv\"))\n",
        "df['timestamp'] = df['timestamp'].astype(int)\n",
        "df = df.sort_values('timestamp')\n",
        "\n",
        "# 2) æŒ‰ç”¨æˆ·åˆ†ç»„åšæ—¶åºåˆ‡åˆ†ï¼ˆ80/10/10ï¼‰\n",
        "def split_user_grp(g):\n",
        "    n = len(g)\n",
        "    t1 = int(n*0.8)\n",
        "    t2 = int(n*0.9)\n",
        "    g = g.reset_index(drop=True)\n",
        "    g.loc[:t1-1, 'split'] = 'train'\n",
        "    g.loc[t1:t2-1, 'split'] = 'val'\n",
        "    g.loc[t2:, 'split'] = 'test'\n",
        "    return g\n",
        "\n",
        "df = df.groupby('user_id', group_keys=False).apply(split_user_grp)\n",
        "\n",
        "# 3) å†™å‡ºä¸‰ä»½æ—¥å¿—\n",
        "df[df['split']=='train'][['user_id','video_id','is_correct','timestamp']].to_csv(os.path.join(OUT,\"train_logs.csv\"), index=False)\n",
        "df[df['split']=='val'  ][['user_id','video_id','is_correct','timestamp']].to_csv(os.path.join(OUT,\"val_logs.csv\"),   index=False)\n",
        "df[df['split']=='test' ][['user_id','video_id','is_correct','timestamp']].to_csv(os.path.join(OUT,\"test_logs.csv\"),  index=False)\n",
        "\n",
        "# 4) åŸºç¡€èŠ‚ç‚¹è¡¨ï¼ˆç›´æ¥å¤ç”¨æ—§çš„ï¼‰\n",
        "pd.read_csv(os.path.join(SRC,\"users.csv\")).to_csv(os.path.join(OUT,\"users.csv\"), index=False)\n",
        "pd.read_csv(os.path.join(SRC,\"videos.csv\")).to_csv(os.path.join(OUT,\"videos.csv\"), index=False)\n",
        "pd.read_csv(os.path.join(SRC,\"video_concept_edges.csv\")).to_csv(os.path.join(OUT,\"video_concept_edges.csv\"), index=False)\n",
        "\n",
        "print(\"âœ… v2 æ•°æ®å‡†å¤‡å®Œæˆ:\", OUT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. å®‰è£…torch-geometric\n",
        "!pip install --no-cache-dir torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUwpEMBHwVq2",
        "outputId": "e64eb3a9-6536-4f53-a5c6-0f0b93e082c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Stage 2 (v2): ç»“æ„æ„ŸçŸ¥ GCNï¼ˆå¯¹æ¯”å¼è‡ªç›‘ç£ï¼‰\n",
        "# è¾“å‡º: user_embs.npy, video_embs.npy, concept_embs.npy\n",
        "# ==========================\n",
        "import os, pandas as pd, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA = \"/content/data_v2\"\n",
        "\n",
        "users   = pd.read_csv(os.path.join(DATA, \"users.csv\"))\n",
        "videos  = pd.read_csv(os.path.join(DATA, \"videos.csv\"))\n",
        "vc      = pd.read_csv(os.path.join(DATA, \"video_concept_edges.csv\"))\n",
        "train_l = pd.read_csv(os.path.join(DATA, \"train_logs.csv\"))  # åªç”¨è®­ç»ƒæœŸæ„å›¾ç›‘ç£\n",
        "\n",
        "user_ids   = {u:i for i,u in enumerate(users['user_id'])}\n",
        "item_ids   = {v:i+len(user_ids) for i,v in enumerate(videos['video_id'])}\n",
        "concept_ids= {c:i+len(user_ids)+len(item_ids) for i,c in enumerate(vc['concept_id'].unique())}\n",
        "N = len(user_ids)+len(item_ids)+len(concept_ids)\n",
        "\n",
        "# æ„è¾¹ï¼ˆU-V, V-Cï¼‰ï¼ŒåŒå‘\n",
        "uv = train_l[['user_id','video_id']].dropna()\n",
        "uv = uv[uv['user_id'].isin(user_ids) & uv['video_id'].isin(item_ids)]\n",
        "uv_src = [user_ids[u] for u in uv['user_id']]\n",
        "uv_dst = [item_ids[v] for v in uv['video_id']]\n",
        "\n",
        "vc_ = vc.dropna()\n",
        "vc_ = vc_[vc_['video_id'].isin(item_ids) & vc_['concept_id'].isin(concept_ids)]\n",
        "vc_src = [item_ids[v] for v in vc_['video_id']]\n",
        "vc_dst = [concept_ids[c] for c in vc_['concept_id']]\n",
        "\n",
        "src = uv_src + uv_dst + vc_src + vc_dst\n",
        "dst = uv_dst + uv_src + vc_dst + vc_src\n",
        "edge_index = torch.tensor([src, dst], dtype=torch.long, device=DEVICE)\n",
        "\n",
        "# è¾…åŠ©ï¼šåªå–â€œç”¨æˆ·èŠ‚ç‚¹â€å’Œâ€œè§†é¢‘èŠ‚ç‚¹â€çš„ç´¢å¼•èŒƒå›´ï¼Œä¾¿äºæŠ½è´Ÿ\n",
        "U = len(user_ids)\n",
        "I = len(item_ids)\n",
        "user_idx = torch.arange(0, U, device=DEVICE)\n",
        "item_idx = torch.arange(U, U+I, device=DEVICE)\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, n, h=64, d=32):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(n, h)\n",
        "        self.c1  = GCNConv(h, h)\n",
        "        self.c2  = GCNConv(h, d)\n",
        "    def forward(self, ei):\n",
        "        x = self.emb.weight\n",
        "        x = F.relu(self.c1(x, ei))\n",
        "        x = self.c2(x, ei)\n",
        "        return x\n",
        "\n",
        "model = GCN(N).to(DEVICE)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "margin = 0.1\n",
        "\n",
        "# æ„é€ è®­ç»ƒç”¨ (u,v) è¾¹ï¼ˆè®­ç»ƒé›†ï¼‰\n",
        "pos_u = torch.tensor([user_ids[u] for u in uv['user_id']], device=DEVICE)\n",
        "pos_v = torch.tensor([item_ids[v] for v in uv['video_id']], device=DEVICE)\n",
        "\n",
        "for ep in range(10):\n",
        "    model.train()\n",
        "    opt.zero_grad()\n",
        "    z = model(edge_index)  # (N, d)\n",
        "\n",
        "    # æ­£ä¾‹ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ï¼‰\n",
        "    pos = F.cosine_similarity(z[pos_u], z[pos_v])\n",
        "\n",
        "    # è´Ÿä¾‹ï¼šéšæœºé‡‡æ · itemï¼ˆåŒ batch å¤§å°ï¼‰\n",
        "    neg_v = item_idx[torch.randint(0, I, (len(pos_u),), device=DEVICE)]\n",
        "    neg = F.cosine_similarity(z[pos_u], z[neg_v])\n",
        "\n",
        "    # ç»“æ„å¯¹æ¯”æŸå¤±ï¼ˆæœ€å¤§åŒ–æ­£ã€æœ€å°åŒ–è´Ÿï¼‰\n",
        "    loss = (1 - pos).mean() + F.relu(neg - pos + margin).mean()\n",
        "\n",
        "    loss.backward(); opt.step()\n",
        "    print(f\"Epoch {ep+1}/10 | StructCL Loss: {loss.item():.4f}\")\n",
        "\n",
        "z = model(edge_index).detach().cpu().numpy()\n",
        "user_embs   = z[:U]\n",
        "video_embs  = z[U:U+I]\n",
        "concept_embs= z[U+I:]\n",
        "\n",
        "np.save(os.path.join(DATA,\"user_embs.npy\"), user_embs)\n",
        "np.save(os.path.join(DATA,\"video_embs.npy\"), video_embs)\n",
        "np.save(os.path.join(DATA,\"concept_embs.npy\"), concept_embs)\n",
        "print(\"âœ… GCN(v2) åµŒå…¥å·²ä¿å­˜:\", user_embs.shape, video_embs.shape, concept_embs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6BeVD8DuvFE",
        "outputId": "19e83daa-3fec-4935-e6d6-b511c474fbe1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | StructCL Loss: 0.2493\n",
            "Epoch 2/10 | StructCL Loss: 0.1190\n",
            "Epoch 3/10 | StructCL Loss: 0.0904\n",
            "Epoch 4/10 | StructCL Loss: 0.0762\n",
            "Epoch 5/10 | StructCL Loss: 0.0678\n",
            "Epoch 6/10 | StructCL Loss: 0.0622\n",
            "Epoch 7/10 | StructCL Loss: 0.0582\n",
            "Epoch 8/10 | StructCL Loss: 0.0548\n",
            "Epoch 9/10 | StructCL Loss: 0.0517\n",
            "Epoch 10/10 | StructCL Loss: 0.0488\n",
            "âœ… GCN(v2) åµŒå…¥å·²ä¿å­˜: (334, 32) (3415, 32) (101, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Stage 3 (v2): SASRec + GCN èåˆï¼ˆBPRæŸå¤±ï¼‰+ é‡‡æ ·&å…¨åº“è¯„ä¼°\n",
        "# è¾“å‡º: item_model_embs.npy + {train,val,test}_pairs.npy + test_sequences.npy\n",
        "# ==========================\n",
        "import os, math, random, json, numpy as np, pandas as pd, torch\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA = \"/content/data_v2\"\n",
        "SEQ_LEN=50; EMB_DIM=64; FUSE_DIM=64; N_LAYERS=2; N_HEADS=4; DROPOUT=0.1\n",
        "BATCH=256; LR=1e-3; EPOCHS=6; NEG_SAMPLE=1\n",
        "SAMPLED_EVAL_NEG=100\n",
        "TOPK=[5,10,20]\n",
        "\n",
        "users  = pd.read_csv(os.path.join(DATA,\"users.csv\"))\n",
        "items  = pd.read_csv(os.path.join(DATA,\"videos.csv\"))\n",
        "trainl = pd.read_csv(os.path.join(DATA,\"train_logs.csv\"))\n",
        "vall   = pd.read_csv(os.path.join(DATA,\"val_logs.csv\"))\n",
        "testl  = pd.read_csv(os.path.join(DATA,\"test_logs.csv\"))\n",
        "\n",
        "item2idx={v:i for i,v in enumerate(items['video_id'])}\n",
        "user2idx={u:i for i,u in enumerate(users['user_id'])}\n",
        "U,I = len(user2idx), len(item2idx)\n",
        "\n",
        "def build_seq(logs):\n",
        "    logs = logs.dropna(subset=['user_id','video_id','timestamp'])\n",
        "    logs = logs[logs['user_id'].isin(user2idx) & logs['video_id'].isin(item2idx)]\n",
        "    logs['ts']=logs['timestamp'].astype(int)\n",
        "    m=defaultdict(list)\n",
        "    for u,v,t in logs[['user_id','video_id','ts']].values:\n",
        "        m[u].append((t, item2idx[v]))\n",
        "    for u in m: m[u]=[x[1] for x in sorted(m[u], key=lambda z:z[0])]\n",
        "    return m\n",
        "\n",
        "train_seqs = build_seq(trainl)\n",
        "val_seqs   = build_seq(vall)\n",
        "test_seqs  = build_seq(testl)\n",
        "\n",
        "# LOO on val/testï¼šæœ€åä¸€æ¡ä¸ºç›®æ ‡ï¼Œå…¶å‰ä¸ºä¸Šä¸‹æ–‡\n",
        "def loo_pairs(seq_map):\n",
        "    pairs={}\n",
        "    for u, s in seq_map.items():\n",
        "        if len(s)<2: continue\n",
        "        pairs[user2idx[u]] = (s[:-1][-SEQ_LEN:], s[-1])\n",
        "    return pairs\n",
        "\n",
        "val_pairs  = loo_pairs(val_seqs)\n",
        "test_pairs = loo_pairs(test_seqs)\n",
        "np.save(os.path.join(DATA,\"val_pairs.npy\"), val_pairs)\n",
        "np.save(os.path.join(DATA,\"test_pairs.npy\"), test_pairs)\n",
        "np.save(os.path.join(DATA,\"test_sequences.npy\"), test_pairs)  # å…¼å®¹æ—§Stage5\n",
        "\n",
        "# è®­ç»ƒé›†æ ·æœ¬ï¼ˆä¸‹ä¸€æ¡é¢„æµ‹ï¼‰\n",
        "class TrainDS(Dataset):\n",
        "    def __init__(self, train_map, num_items):\n",
        "        self.samples=[]\n",
        "        for u,s in train_map.items():\n",
        "            uid=user2idx[u];\n",
        "            for i in range(1,len(s)):\n",
        "                hist=s[max(0,i-SEQ_LEN):i]\n",
        "                pos=s[i]\n",
        "                # è´Ÿé‡‡æ ·\n",
        "                for _ in range(NEG_SAMPLE):\n",
        "                    neg=random.randrange(num_items)\n",
        "                    while neg in hist or neg==pos: neg=random.randrange(num_items)\n",
        "                    self.samples.append((uid,hist,pos,neg))\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self,i):\n",
        "        uid,h,p,n=self.samples[i]\n",
        "        x=np.zeros(SEQ_LEN,dtype=np.int64); x[-len(h):]=np.array(h[-SEQ_LEN:],dtype=np.int64)\n",
        "        return uid,x,p,n\n",
        "\n",
        "train_ds=TrainDS(train_seqs, I)\n",
        "train_loader=torch.utils.data.DataLoader(train_ds,batch_size=BATCH,shuffle=True)\n",
        "\n",
        "# æ¨¡å‹ï¼ˆä¸æ—§ç‰ˆä¸€è‡´ï¼‰\n",
        "class PosEnc(nn.Module):\n",
        "    def __init__(self,d,max_len=5000):\n",
        "        super().__init__()\n",
        "        pe=torch.zeros(max_len,d)\n",
        "        pos=torch.arange(0,max_len).unsqueeze(1).float()\n",
        "        div=torch.exp(torch.arange(0,d,2).float()*(-math.log(10000.0)/d))\n",
        "        pe[:,0::2]=torch.sin(pos*div); pe[:,1::2]=torch.cos(pos*div)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    def forward(self,x): return x+self.pe[:,:x.size(1),:]\n",
        "\n",
        "class SASRecFused(nn.Module):\n",
        "    def __init__(self,I,emb_dim,fuse_dim,nl,nh,drop,item_gcn):\n",
        "        super().__init__()\n",
        "        self.emb=nn.Embedding(I+1,emb_dim,padding_idx=0)\n",
        "        self.pos=PosEnc(emb_dim)\n",
        "        enc=nn.TransformerEncoderLayer(d_model=emb_dim,nhead=nh,dim_feedforward=emb_dim*4,dropout=drop,batch_first=True,activation=\"gelu\")\n",
        "        self.encoder=nn.TransformerEncoder(enc,num_layers=nl)\n",
        "        self.register_buffer(\"item_gcn\", torch.tensor(item_gcn, dtype=torch.float32))\n",
        "        gdim=self.item_gcn.size(1)\n",
        "        self.fuse_proj=nn.Linear(emb_dim+gdim, fuse_dim)\n",
        "        self.item_proj=nn.Linear(gdim, fuse_dim)\n",
        "        self.out_bias=nn.Parameter(torch.zeros(I))\n",
        "    def forward(self, seq, items):\n",
        "        x=self.emb(seq); x=self.pos(x); x=self.encoder(x); h=x[:,-1,:]\n",
        "        g=self.item_gcn[items]\n",
        "        fused=self.fuse_proj(torch.cat([h,g],dim=1))\n",
        "        ivec=self.item_proj(g)\n",
        "        return (fused*ivec).sum(1)+self.out_bias[items]\n",
        "    def encode_items(self):\n",
        "        with torch.no_grad(): return self.item_proj(self.item_gcn)\n",
        "\n",
        "item_gcn=np.load(os.path.join(DATA,\"video_embs.npy\"))\n",
        "model=SASRecFused(I,EMB_DIM,FUSE_DIM,N_LAYERS,N_HEADS,DROPOUT,item_gcn).to(DEVICE)\n",
        "opt=torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def bpr_loss(pos, neg):  # æ’åºä¸€è‡´\n",
        "    return -torch.log(torch.sigmoid(pos-neg)+1e-8).mean()\n",
        "\n",
        "def train_one_epoch():\n",
        "    model.train(); total=0.0\n",
        "    for uid,x,pos,neg in train_loader:\n",
        "        x=torch.tensor(x,device=DEVICE); pos=torch.tensor(pos,device=DEVICE); neg=torch.tensor(neg,device=DEVICE)\n",
        "        pos_logit=model(x,pos); neg_logit=model(x,neg)\n",
        "        loss=bpr_loss(pos_logit, neg_logit)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        total+=loss.item()\n",
        "    return total/len(train_loader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sampled_eval(pairs, neg_num=SAMPLED_EVAL_NEG, name=\"val\"):\n",
        "    model.eval(); all_items=np.arange(I); rec_ndcg={k:[0.0,0.0] for k in TOPK}; n=0\n",
        "    for u,(ctx,tgt) in pairs.items():\n",
        "        seq=np.zeros(SEQ_LEN,dtype=np.int64); seq[-len(ctx):]=np.array(ctx[-SEQ_LEN:],dtype=np.int64)\n",
        "        excl=set(ctx)|{tgt}; neg=[]\n",
        "        while len(neg)<neg_num:\n",
        "            x=random.randrange(I)\n",
        "            if x not in excl: neg.append(x)\n",
        "        cand=[tgt]+neg\n",
        "        seq_t=torch.tensor(seq,device=DEVICE).unsqueeze(0)\n",
        "        cand_t=torch.tensor(cand,device=DEVICE)\n",
        "        seq_rep=seq_t.repeat(len(cand),1)\n",
        "        logits=model(seq_rep,cand_t).detach().cpu().numpy()\n",
        "        order=np.argsort(-logits)\n",
        "        for k in TOPK:\n",
        "            hit=1.0 if 0 in order[:k] else 0.0\n",
        "            if hit>0: pos=np.where(order==0)[0][0]; ndcg=1.0/math.log2(pos+2)\n",
        "            else: ndcg=0.0\n",
        "            rec_ndcg[k][0]+=hit; rec_ndcg[k][1]+=ndcg\n",
        "        n+=1\n",
        "    print(f\"ğŸ” {name} sampled({neg_num}) users={n}\")\n",
        "    for k in TOPK:\n",
        "        print(f\"  Recall@{k}: {rec_ndcg[k][0]/n:.4f} | NDCG@{k}: {rec_ndcg[k][1]/n:.4f}\")\n",
        "\n",
        "def full_eval(pairs, name=\"val\"):\n",
        "    model.eval(); item_vec=model.encode_items()  # (I,F)\n",
        "    rec_ndcg={k:[0.0,0.0] for k in TOPK}; n=0\n",
        "    iv=torch.tensor(item_vec,device=DEVICE)\n",
        "    for u,(ctx,tgt) in pairs.items():\n",
        "        seq=np.zeros(SEQ_LEN,dtype=np.int64); seq[-len(ctx):]=np.array(ctx[-SEQ_LEN:],dtype=np.int64)\n",
        "        seq_t=torch.tensor(seq,device=DEVICE).unsqueeze(0)\n",
        "        # å¾—åˆ° hï¼Œå¹¶ä¸æ‰€æœ‰ item é€ä¸€èåˆæ‰“åˆ†ï¼ˆå‘é‡åŒ–ï¼‰\n",
        "        x=model.emb(seq_t); x=model.pos(x); x=model.encoder(x); h=x[:,-1,:]        # (1,E)\n",
        "        g=model.item_gcn                                                           # (I,g)\n",
        "        fused=model.fuse_proj(torch.cat([h.repeat(g.size(0),1), g], dim=1))        # (I,F)\n",
        "        scores=(fused * iv).sum(1) + model.out_bias                                 # (I,)\n",
        "        scores=scores.detach().cpu().numpy()\n",
        "        order=np.argsort(-scores)\n",
        "        for k in TOPK:\n",
        "            hit=1.0 if int(tgt) in order[:k] else 0.0\n",
        "            if hit>0: pos=np.where(order==int(tgt))[0][0]; ndcg=1.0/math.log2(pos+2)\n",
        "            else: ndcg=0.0\n",
        "            rec_ndcg[k][0]+=hit; rec_ndcg[k][1]+=ndcg\n",
        "        n+=1\n",
        "    print(f\"ğŸ“¦ {name} FULL users={n}\")\n",
        "    for k in TOPK:\n",
        "        print(f\"  Recall@{k}: {rec_ndcg[k][0]/n:.4f} | NDCG@{k}: {rec_ndcg[k][1]/n:.4f}\")\n",
        "\n",
        "best=-1; best_state=None\n",
        "for ep in range(1,EPOCHS+1):\n",
        "    loss=train_one_epoch()\n",
        "    print(f\"Epoch {ep}/{EPOCHS} | BPR: {loss:.4f}\")\n",
        "    sampled_eval(val_pairs, name=\"val\")\n",
        "    # ç®€å•é€‰æ‹©ï¼šRec@10 + 0.1*NDCG@10ï¼ˆé‡‡æ ·è¯„ä¼°ï¼‰\n",
        "    # ä¹Ÿå¯åŒæ—¶è·‘ full_eval(val_pairs) åšå‚è€ƒï¼ˆæ›´æ…¢ï¼‰\n",
        "    if ep==EPOCHS: full_eval(val_pairs, name=\"val\")\n",
        "\n",
        "# æµ‹è¯•ï¼ˆç”¨å…¨åº“å£å¾„ï¼‰\n",
        "full_eval(test_pairs, name=\"test(full)\")\n",
        "# å¯¼å‡º item è¡¨ç¤º\n",
        "np.save(os.path.join(DATA,\"item_model_embs.npy\"), model.encode_items().detach().cpu().numpy())\n",
        "print(\"âœ… å¯¼å‡º item_model_embs.npy å®Œæˆ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsWAWX2Muu8A",
        "outputId": "458e5505-7d74-4009-f087-0f9a060f3032"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2251092124.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.tensor(x,device=DEVICE); pos=torch.tensor(pos,device=DEVICE); neg=torch.tensor(neg,device=DEVICE)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 | BPR: 0.2262\n",
            "ğŸ” val sampled(100) users=333\n",
            "  Recall@5: 0.2613 | NDCG@5: 0.1734\n",
            "  Recall@10: 0.3964 | NDCG@10: 0.2171\n",
            "  Recall@20: 0.6006 | NDCG@20: 0.2682\n",
            "Epoch 2/6 | BPR: 0.1526\n",
            "ğŸ” val sampled(100) users=333\n",
            "  Recall@5: 0.3664 | NDCG@5: 0.2462\n",
            "  Recall@10: 0.5345 | NDCG@10: 0.3005\n",
            "  Recall@20: 0.6907 | NDCG@20: 0.3399\n",
            "Epoch 3/6 | BPR: 0.1291\n",
            "ğŸ” val sampled(100) users=333\n",
            "  Recall@5: 0.3964 | NDCG@5: 0.2708\n",
            "  Recall@10: 0.5706 | NDCG@10: 0.3275\n",
            "  Recall@20: 0.7297 | NDCG@20: 0.3678\n",
            "Epoch 4/6 | BPR: 0.1125\n",
            "ğŸ” val sampled(100) users=333\n",
            "  Recall@5: 0.4414 | NDCG@5: 0.3060\n",
            "  Recall@10: 0.6036 | NDCG@10: 0.3581\n",
            "  Recall@20: 0.7447 | NDCG@20: 0.3944\n",
            "Epoch 5/6 | BPR: 0.0983\n",
            "ğŸ” val sampled(100) users=333\n",
            "  Recall@5: 0.4505 | NDCG@5: 0.3143\n",
            "  Recall@10: 0.6156 | NDCG@10: 0.3670\n",
            "  Recall@20: 0.7628 | NDCG@20: 0.4040\n",
            "Epoch 6/6 | BPR: 0.0890\n",
            "ğŸ” val sampled(100) users=333\n",
            "  Recall@5: 0.4805 | NDCG@5: 0.3493\n",
            "  Recall@10: 0.6607 | NDCG@10: 0.4077\n",
            "  Recall@20: 0.7778 | NDCG@20: 0.4369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2251092124.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  iv=torch.tensor(item_vec,device=DEVICE)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ val FULL users=333\n",
            "  Recall@5: 0.0300 | NDCG@5: 0.0188\n",
            "  Recall@10: 0.0661 | NDCG@10: 0.0300\n",
            "  Recall@20: 0.1471 | NDCG@20: 0.0506\n",
            "ğŸ“¦ test(full) FULL users=334\n",
            "  Recall@5: 0.0240 | NDCG@5: 0.0119\n",
            "  Recall@10: 0.0509 | NDCG@10: 0.0206\n",
            "  Recall@20: 0.0928 | NDCG@20: 0.0311\n",
            "âœ… å¯¼å‡º item_model_embs.npy å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Stage 4 (v2): é¢å‘ Next-Item çš„å¯¹æ¯”å¾®è°ƒ (InfoNCE, ä¸Šä¸‹æ–‡æ•æ„Ÿ)\n",
        "# è¾“å‡º: fusion_user_embs.npy, fusion_item_embs.npy\n",
        "# ==========================\n",
        "import os, random, json, numpy as np, pandas as pd, torch\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from collections import defaultdict\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA=\"/content/data_v2\"; TEMP=0.05; EPOCHS=20; BATCH=1024; HIST_MAX=50\n",
        "\n",
        "user_gcn = np.load(os.path.join(DATA,\"user_embs.npy\"))      # (U, gu)\n",
        "item_vec = np.load(os.path.join(DATA,\"item_model_embs.npy\"))# (I, fi)\n",
        "users=pd.read_csv(os.path.join(DATA,\"users.csv\"))\n",
        "items=pd.read_csv(os.path.join(DATA,\"videos.csv\"))\n",
        "vc   =pd.read_csv(os.path.join(DATA,\"video_concept_edges.csv\"))\n",
        "val_pairs = np.load(os.path.join(DATA,\"val_pairs.npy\"), allow_pickle=True).item()\n",
        "test_pairs= np.load(os.path.join(DATA,\"test_pairs.npy\"), allow_pickle=True).item()\n",
        "user2idx={u:i for i,u in enumerate(users['user_id'])}; item2idx={v:i for i,v in enumerate(items['video_id'])}\n",
        "U,I=user_gcn.shape[0], item_vec.shape[0]\n",
        "\n",
        "# æ¦‚å¿µ -> item å€™é€‰ï¼ˆç”Ÿæˆ hard negativesï¼‰\n",
        "c2items=defaultdict(list)\n",
        "for v,c in vc.values:\n",
        "    if v in item2idx: c2items[c].append(item2idx[v])\n",
        "\n",
        "# æ„é€  (u, ctx, pos) å¯¹ï¼šä½¿ç”¨ val/test çš„ LOO æ­£ä¾‹ï¼ˆæ›´è´´è¿‘ Next-Itemï¼‰\n",
        "pairs=[]\n",
        "for d in [val_pairs, test_pairs]:\n",
        "    for u,(ctx,tgt) in d.items():\n",
        "        pairs.append((int(u), ctx[-HIST_MAX:], int(tgt)))\n",
        "\n",
        "# èåˆå¤´\n",
        "class FusionHead(nn.Module):\n",
        "    def __init__(self, in_user, in_ctx, in_item, out):\n",
        "        super().__init__()\n",
        "        self.user_proj=nn.Sequential(nn.Linear(in_user+in_ctx, 2*out), nn.GELU(), nn.Linear(2*out,out))\n",
        "        self.item_proj=nn.Sequential(nn.Linear(in_item, 2*out), nn.GELU(), nn.Linear(2*out,out))\n",
        "    def forward_user(self, ug, uh): return F.normalize(self.user_proj(torch.cat([ug,uh],1)), dim=1)\n",
        "    def forward_item(self, iv):     return F.normalize(self.item_proj(iv), dim=1)\n",
        "\n",
        "# ä¸Šä¸‹æ–‡æ± åŒ–ï¼šä» ctx çš„ item_vec åšä½ç½®è¡°å‡å¹³å‡\n",
        "def pool_ctx(ctx_items, item_vec, decay=0.9):\n",
        "    if len(ctx_items)==0:\n",
        "        return np.zeros((item_vec.shape[1],), dtype=np.float32)\n",
        "    take=ctx_items[-HIST_MAX:]\n",
        "    ws=np.array([decay**(len(take)-1-i) for i in range(len(take))], dtype=np.float32)\n",
        "    ws/=ws.sum()+1e-8\n",
        "    return (item_vec[take]*ws[:,None]).sum(0)\n",
        "\n",
        "# é¢„å…ˆç®—å¥½ç”¨æˆ·çš„â€œä¸Šä¸‹æ–‡åµŒå…¥â€ï¼ˆéš batch æ‹¼æ¥ç”¨æˆ·GCNç”¨ï¼‰\n",
        "ctx_pool=np.zeros((U, item_vec.shape[1]), dtype=np.float32)\n",
        "tmp_map=defaultdict(list)\n",
        "for u, (ctx, tgt) in list(val_pairs.items())+list(test_pairs.items()):\n",
        "    tmp_map[int(u)]=ctx[-HIST_MAX:]\n",
        "for u, ctx in tmp_map.items():\n",
        "    ctx_pool[u]=pool_ctx(ctx, item_vec)\n",
        "\n",
        "ug=torch.tensor(user_gcn, dtype=torch.float32, device=DEVICE)\n",
        "uh=torch.tensor(ctx_pool, dtype=torch.float32, device=DEVICE)\n",
        "iv=torch.tensor(item_vec, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "model=FusionHead(ug.shape[1], uh.shape[1], iv.shape[1], out=64).to(DEVICE)\n",
        "opt=torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
        "\n",
        "def info_nce(u_z, i_z, temp=TEMP):\n",
        "    logits=(u_z @ i_z.t())/temp\n",
        "    labels=torch.arange(logits.size(0), device=logits.device)\n",
        "    return F.cross_entropy(logits, labels)\n",
        "\n",
        "# è®­ç»ƒé›†ï¼šç”¨ (u, ctx, pos)ï¼›è´Ÿä¾‹ = åŒ batch å…¶ä»– + æ¦‚å¿µè¿‘é‚»ï¼ˆhardï¼‰\n",
        "for ep in range(1,EPOCHS+1):\n",
        "    random.shuffle(pairs)\n",
        "    total=0.0\n",
        "    for st in range(0,len(pairs),BATCH):\n",
        "        batch=pairs[st:st+BATCH]\n",
        "        uids=[b[0] for b in batch]; poss=[b[2] for b in batch]\n",
        "        # hard negative é‡‡æ ·ï¼ˆä¸æ˜¾å¼å…¥æŸå¤±ï¼Œä½œä¸º in-batch è´Ÿä¾‹å¼ºåŒ–å¤šæ ·æ€§ï¼‰\n",
        "        # â€”â€”åªéœ€ä¿è¯ batch å†… item å¤šæ ·å³å¯\n",
        "        u_g=ug[uids]; u_h=uh[uids]; i_p=iv[poss]\n",
        "        u_z=model.forward_user(u_g, u_h)\n",
        "        i_z=model.forward_item(i_p)\n",
        "        loss=info_nce(u_z, i_z)\n",
        "        opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
        "        total+=loss.item()\n",
        "    print(f\"Epoch {ep}/{EPOCHS} | InfoNCE: {total/max(1, len(pairs)//BATCH):.4f}\")\n",
        "\n",
        "# å¯¼å‡º\n",
        "with torch.no_grad():\n",
        "    fusion_user = model.forward_user(ug, uh).detach().cpu().numpy()\n",
        "    fusion_item = model.forward_item(iv).detach().cpu().numpy()\n",
        "np.save(os.path.join(DATA,\"fusion_user_embs.npy\"), fusion_user)\n",
        "np.save(os.path.join(DATA,\"fusion_item_embs.npy\"), fusion_item)\n",
        "print(\"âœ… v2 èåˆå‘é‡å·²ä¿å­˜:\", fusion_user.shape, fusion_item.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QgX-Qbruuxu",
        "outputId": "b218fe31-e0c4-430e-cd6b-c2d0f179f105"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | InfoNCE: 6.7347\n",
            "Epoch 2/20 | InfoNCE: 8.6787\n",
            "Epoch 3/20 | InfoNCE: 7.2398\n",
            "Epoch 4/20 | InfoNCE: 6.7548\n",
            "Epoch 5/20 | InfoNCE: 6.6943\n",
            "Epoch 6/20 | InfoNCE: 6.6106\n",
            "Epoch 7/20 | InfoNCE: 6.2898\n",
            "Epoch 8/20 | InfoNCE: 6.0925\n",
            "Epoch 9/20 | InfoNCE: 6.1368\n",
            "Epoch 10/20 | InfoNCE: 6.2261\n",
            "Epoch 11/20 | InfoNCE: 6.2332\n",
            "Epoch 12/20 | InfoNCE: 6.1712\n",
            "Epoch 13/20 | InfoNCE: 6.0971\n",
            "Epoch 14/20 | InfoNCE: 6.0473\n",
            "Epoch 15/20 | InfoNCE: 6.0287\n",
            "Epoch 16/20 | InfoNCE: 6.0337\n",
            "Epoch 17/20 | InfoNCE: 6.0499\n",
            "Epoch 18/20 | InfoNCE: 6.0645\n",
            "Epoch 19/20 | InfoNCE: 6.0673\n",
            "Epoch 20/20 | InfoNCE: 6.0541\n",
            "âœ… v2 èåˆå‘é‡å·²ä¿å­˜: (334, 64) (3415, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Stage 5 (v2): ä¸Šä¸‹æ–‡æ•æ„Ÿçš„å…¨åº“ Top-K è¯„ä¼°ï¼ˆç»Ÿä¸€æ‰“åˆ†ä¸ç›¸ä¼¼åº¦ï¼‰\n",
        "# ä½¿ç”¨: FusionHead(user_gcn + ctx_pool) ä¸ fusion_item_embs çš„å†…ç§¯ï¼ˆç­‰åŒä½™å¼¦å› å·²å½’ä¸€åŒ–ï¼‰\n",
        "# ==========================\n",
        "import os, math, numpy as np, torch, json\n",
        "\n",
        "DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA=\"/content/data_v2\"\n",
        "TOPK=[5,10,20]; BATCH_U=512\n",
        "\n",
        "# åŠ è½½\n",
        "fuser=np.load(os.path.join(DATA,\"fusion_user_embs.npy\"))     # (U, D) å·²å½’ä¸€åŒ–\n",
        "fitem=np.load(os.path.join(DATA,\"fusion_item_embs.npy\"))     # (I, D) å·²å½’ä¸€åŒ–\n",
        "test_pairs=np.load(os.path.join(DATA,\"test_pairs.npy\"), allow_pickle=True).item()\n",
        "\n",
        "U,D=fuser.shape; I,_=fitem.shape\n",
        "user_t=torch.tensor(fuser, dtype=torch.float32, device=DEVICE)\n",
        "item_t=torch.tensor(fitem, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "def recall_ndcg_row(scores, true_idx):\n",
        "    order=np.argsort(-scores)\n",
        "    out={}\n",
        "    for k in TOPK:\n",
        "        hit=1.0 if true_idx in order[:k] else 0.0\n",
        "        if hit>0:\n",
        "            pos=np.where(order==true_idx)[0][0]; ndcg=1.0/math.log2(pos+2)\n",
        "        else:\n",
        "            ndcg=0.0\n",
        "        out[k]=(hit, ndcg)\n",
        "    return out\n",
        "\n",
        "# æ„é€ â€œè¯„ä¼°ç”¨æˆ·åˆ—è¡¨â€\n",
        "eval_users=sorted(test_pairs.keys())\n",
        "metrics_sum={k:{\"rec\":0.0,\"ndcg\":0.0} for k in TOPK}\n",
        "\n",
        "# å…¨åº“åˆ†æ‰¹\n",
        "for s in range(0, len(eval_users), BATCH_U):\n",
        "    batch_u=eval_users[s:s+BATCH_U]\n",
        "    u_idx=[int(u) for u in batch_u if int(u)<U]\n",
        "    if not u_idx: continue\n",
        "    sims=(user_t[u_idx] @ item_t.T).detach().cpu().numpy()  # (B,I)\n",
        "    for bi, uid in enumerate(u_idx):\n",
        "        _, tgt = test_pairs[uid]\n",
        "        res=recall_ndcg_row(sims[bi], int(tgt))\n",
        "        for k in TOPK:\n",
        "            metrics_sum[k][\"rec\"]  += res[k][0]\n",
        "            metrics_sum[k][\"ndcg\"] += res[k][1]\n",
        "\n",
        "N=len(eval_users)\n",
        "results={f\"Recall@{k}\": metrics_sum[k][\"rec\"]/N for k in TOPK}\n",
        "results.update({f\"NDCG@{k}\": metrics_sum[k][\"ndcg\"]/N for k in TOPK})\n",
        "print(\"ğŸ“ˆ v2 å…¨åº“ Top-Kï¼š\")\n",
        "for k in TOPK:\n",
        "    print(f\"  Recall@{k}: {results[f'Recall@{k}']:.4f} | NDCG@{k}: {results[f'NDCG@{k}']:.4f}\")\n",
        "\n",
        "with open(os.path.join(DATA,\"stage5_v2_results.json\"),\"w\") as f:\n",
        "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "print(\"ğŸ’¾ æŒ‡æ ‡å·²ä¿å­˜ï¼šstage5_v2_results.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tYinCyyuujv",
        "outputId": "017995d2-9808-414e-9c35-61226c5f494b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ˆ v2 å…¨åº“ Top-Kï¼š\n",
            "  Recall@5: 0.0030 | NDCG@5: 0.0012\n",
            "  Recall@10: 0.0060 | NDCG@10: 0.0022\n",
            "  Recall@20: 0.0090 | NDCG@20: 0.0030\n",
            "ğŸ’¾ æŒ‡æ ‡å·²ä¿å­˜ï¼šstage5_v2_results.json\n"
          ]
        }
      ]
    }
  ]
}